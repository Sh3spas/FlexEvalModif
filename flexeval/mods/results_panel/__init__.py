# coding: utf8
# license : CeCILL-C


#######################################
#               IMPORTS               #
#######################################

import json
import os
import string
import random
import shutil
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime   

from flask import current_app, request,send_file
from sqlalchemy import MetaData, Table

from flexeval.core import AdminModule
from flexeval.utils import redirect,make_global_url,safe_make_rep
from flexeval.database import Model,db

from math import sqrt
#######################################
#               CONSTANTS             #
#######################################

# AB constants
AB_TEST_TYPES = ["ab", "abx"] # List of the possible types of AB tests
INTRO_COLUMN_NAME = "intro" # Name of the column containing the intro boolean
MEDIA_1_COLUMN_NAME = "sys1" # Name of the column containing the first media
MEDIA_2_COLUMN_NAME = "sys2" # Name of the column containing the second media
AB_CHOICE_COLUMN_NAME = "ChoiceBetween_sys1_sys2" # Name of the column containing the choice between the two media
# AB_CHOICE_COLUMN_NAME = "ChoiceBetween" # Name of the column containing the choice between the two media
AB_COUNT_NAME = "count"
AB_SYSTEM_NAME = "system"

# MOS constants
MOS_TEST_TYPES = ["mos", "dmos"] # List of the possible types of MOS tests
MOS_SCORE_NAME = "moyenne" # Name of the column containing the MOS score
MOS_CONFIDENCE_INTERVAL_NAME = "intervalle_confiance" # Name of the column containing the confidence interval of the MOS score
MOS_ERROR_LOWER_BOUND_NAME = "erreur_inf" # Name of the column containing the lower bound of the error bar
MOS_ERROR_UPPER_BOUND_NAME = "erreur_sup" # Name of the column containing the upper bound of the error bar
MOS_MIN_SCORE = 1 # Minimum score of the MOS test
MOS_MAX_SCORE = 5 # Maximum score of the MOS test

# MUSHRA constants
MUSHRA_TEST_TYPES = ["mushra"] # List of the possible types of MUSHRA tests
MUSHRA_SCORE_NAME = "moyenne" # Name of the column containing the MUSHRA score
MUSHRA_CONFIDENCE_INTERVAL_NAME = "intervalle_confiance" # Name of the column containing the confidence interval of the MUSHRA score
MUSHRA_ERROR_LOWER_BOUND_NAME = "erreur_inf" # Name of the column containing the lower bound of the error bar
MUSHRA_ERROR_UPPER_BOUND_NAME = "erreur_sup" # Name of the column containing the upper bound of the error bar
MUSHRA_MIN_SCORE = 0 # Minimum score of the MUSHRA test
MUSHRA_MAX_SCORE = 100 # Maximum score of the MUSHRA test

# Results directory
RESULTS_DIR = current_app.config["FLEXEVAL_INSTANCE_RESULTS_DIR"]


#######################################
#              FUNCTIONS              #
#######################################

def update_save_path(save_path):
    """
    This function adds a number to the title of a plot if one with the same name already exists
    :param path: the path of the directory where the file will be saved
    :param title: the title of the plot
    :return: the updated title
    """
    
    if os.path.exists(save_path):
        i = 1
        while os.path.exists(save_path):
            i += 1
        save_path = f'{save_path}({i})'
    return save_path

def get_save_path(test_type, test_name):
    """
    This function generates a save path for the chart of the results of the test
    :param test_type: the type of the test
    :return: the save path
    """
    safe_make_rep(os.path.join(RESULTS_DIR, test_name))
    dateTimeISO = datetime.now().isoformat()
    save_path = update_save_path(os.path.join(RESULTS_DIR, test_name, f"{dateTimeISO}_{test_type}.png"))
    return save_path

def calc_confidence_interval(data):
    """
    This function calculates the confidence interval of the data
    :param data: a list of data
    :return: the confidence interval
    """

    # 1.96 is the z-score for a 95% confidence interval
    # We divide the standard deviation by the square root of the number of samples to get the standard error of the mean
    # We multiply by 1.96 to get the margin of error
    
    return 1.96 * data.std() / sqrt(len(data))

def analyse_results(system_json, test_json, test_type):
    """
    This function generate a pandas dataframe of the data from the test results
    :param system_json: the system data in JSON format
    :param test_json: the test data in JSON format
    :param test_name: the name of the test
    :returns data: a pandas dataframe

    IMPORTANT : This function must be adapted to the format of the data outputed by FlexEval
    It is currently working for old data generated by FlexEval, but it may not work on the new version as it is incomplete
    """
       

    system_data = pd.DataFrame(system_json)
    test_data = pd.DataFrame(test_json)

    if test_type.lower() in AB_TEST_TYPES:
        # TODO add support for more than two systems
        # If sys1 in the choice column, we keep sys1, else we keep sys2
        # Merge the ids with the system data on the id column
        # Count the number of times each system was chosen

        data = test_data[[MEDIA_1_COLUMN_NAME, MEDIA_2_COLUMN_NAME, AB_CHOICE_COLUMN_NAME]]
        ids = pd.DataFrame()
        ids['id'] = data.apply(lambda x: x[MEDIA_1_COLUMN_NAME] if x[AB_CHOICE_COLUMN_NAME] == f"{MEDIA_1_COLUMN_NAME}" else x[MEDIA_2_COLUMN_NAME], axis=1)
        fileMerge = ids.merge(system_data, on='id')[['id', 'system']]                
        data = pd.DataFrame()
        data['count'] = fileMerge['system'].value_counts()



    elif test_type.lower() in MOS_TEST_TYPES:
        # Concatenate the ids and the scores of the two systems
        ids = pd.concat([
            test_data[['sys1', 'MOS_score_sys1']].rename(columns={'sys1': 'id', 'MOS_score_sys1': 'score'}),
            test_data[['sys2', 'MOS_score_sys2']].rename(columns={'sys2': 'id', 'MOS_score_sys2': 'score'})
        ])
        
        # Now get the system names (system) from the system data file corresponding to the ids (id)
        # We can do this by merging the ids with the system data on the id column.
        
        # Merge the ids with the system data on the id column but only keep the id, system name and score columns
        fileMerge = ids.merge(system_data, on='id')[['id', 'system', 'score']]

        # Compute the mean score for each system
        fileMerge['score'] = fileMerge['score'].astype(int) # Convert the score to an integer
        data = fileMerge.groupby('system')['score'].agg(moyenne='mean')

        # Compute the confidence interval for each system
        error_margins = fileMerge.groupby('system')['score'].apply(calc_confidence_interval)
        data[MUSHRA_CONFIDENCE_INTERVAL_NAME] = error_margins

    elif test_type.lower() in MUSHRA_TEST_TYPES:

        ids = pd.concat([
            test_data[['sys1', 'MUSHRA_score_sys1']].rename(columns={'sys1': 'id', 'MUSHRA_score_sys1': 'score'}),
            test_data[['sys2', 'MUSHRA_score_sys2']].rename(columns={'sys2': 'id', 'MUSHRA_score_sys2': 'score'})
        ])
        
        # Now get the system names (system) from the system data file corresponding to the ids (id)
        # We can do this by merging the ids with the system data on the id column.
        
        # Merge the ids with the system data on the id column but only keep the id, system name and score columns
        fileMerge = ids.merge(system_data, on='id')[['id', 'system', 'score']]

        # Compute the mean score for each system
        fileMerge['score'] = fileMerge['score'].astype(int) # Convert the score to an integer
        data = fileMerge.groupby('system')['score'].agg(moyenne='mean')

        # Compute the confidence interval for each system
        # 1.96 is the z-score for a 95% confidence interval
        # We divide by the square root of the number of samples to get the standard error of the mean
        # We multiply by 1.96 to get the margin of error

        error_margins = fileMerge.groupby('system')['score'].apply(calc_confidence_interval)
        data[MUSHRA_CONFIDENCE_INTERVAL_NAME] = error_margins

    else:
        data = None
    
    return data
       
def get_tables():
    """
    This function extracts the tables from the database and turns them into json objects
    """

    # These will store the name of the tables
    usersTable = None
    systemsTable = None
    testsTables = {}

    

    for name_table in db.engine.table_names():
        table = Table(name_table, MetaData(), autoload=True, autoload_with=db.engine)

        # Turn an sqlAlchemy table object into a json object
        json_table = {name_table: []}
        for row in db.session.query(table).all():
            json_table[name_table].append({column.name: str(getattr(row, column.name)) for column in table.columns})

        if name_table.startswith("SystemSample"):                                        
            systemsTable = json_table
        elif name_table.startswith("StageModule_User"):                              
            usersTable = json_table
        elif name_table.startswith("TestSample_") and len(json_table[name_table]) > 0: 
            # Extract the key from the table name
            key = name_table.split("TestSample_")[-1]
            testsTables[key] = json_table  # Add the json table to testsTables with the extracted key


    return usersTable, systemsTable, testsTables


#######################################
#               ROUTES                #
#######################################

with AdminModule(__name__) as am:
    
    @am.route('/')
    @am.connection_required
    def panel():
        """
        Display the results panel module
        """
        
        results_path = current_app.config["FLEXEVAL_INSTANCE_RESULTS_DIR"]
        data_url = make_global_url(results_path+"/csvjson.json")

        usersTable, systemsTable, testsTables = get_tables()
        # FIXME : The keys of testsTables are the name of the tables (e.g. Test_test_ab) turned into the name of the test (e.g. AB).
        # This is a coincidence that AB is both the type and the name of the test. Yet it is required for the current implementation.
        # This should be changed in the future to avoid confusion and to make the code more robust.

        jsons = {}
        for key, value in testsTables.items():
            jsons[f"{key}"] = value
        jsons['Users'] = usersTable
        jsons['Systems'] = systemsTable
        
        # matplotlib plt styles for the dropdown

        available_styles = plt.style.available
        available_styles = [style for style in available_styles if style != "classic"] # remove classic style if it exists
        styles = {style:style.replace("_"," ").replace("-"," ").capitalize() for style in available_styles}

        # matplotlib plt markers for the dropdown
        markers =  plt.Line2D.markers
        markers = {key: value.replace("_"," ").capitalize() for key, value in markers.items()}
        
        # images 
        # images = [all images in a subdir of the results directory]
        images_dict = {}
        results_sub_dirs = [f.path for f in os.scandir(results_path) if f.is_dir()]
        
        for results_sub_dir in results_sub_dirs:
            test_name = results_sub_dir.split('/')[-1]
            for image in os.listdir(results_sub_dir):
                if image.endswith(".png"):
                    date = image.split("T")[0]
                    time = image.split("T")[1].split("_")[0]
                    test_type = image.split('_')[1].replace(".png","").upper()
                    chart_type = image.split('_')[-1].replace(".png","").capitalize()
                    image_relative_path = os.path.join('results', test_name, image)
                    images_dict[image_relative_path] = {
                        "date": date,
                        "time": time,
                        "test_type": test_type,
                        "test_name": test_name,
                        "chart_type": chart_type
                    }

        # Turn images_dict into a json string
        images_dict = json.dumps(images_dict)
        
        # Get the error message from the url parameters
        error = request.args.get("error")

        return am.render_template(
            "panel.tpl",
            jsons=jsons,
            styles=styles,
            markers=markers,
            images_dict=images_dict,
            error=error
        )


    @am.route('/generate_charts', methods=["POST"])
    @am.connection_required
    def generate_charts():
        """
        Form submission to generate charts from the results of the tests
        """
        
        # Get the data from the form
        form = request.form.to_dict()
        
        # Default options
        try:
            use_existing_table_filters = 'use-existing-table-filters' in form
            include_intro_step = 'include-intro-step' in form
            user_select = form['user-select']
            ab_format = form['ab-format']
            chart_title = form['chart-title']
            chart_style = form['chart-style']
            alternate_colors = 'alternate-colors' in form
            marker_type = form['marker-select']
            x_axis_check = 'x-axis-check' in form
            y_axis_check = 'y-axis-check' in form
            x_label = 'Auto' if x_axis_check and form['x-label'] == '' else form['x-label'] if x_axis_check else None
            y_label = 'Auto' if y_axis_check and form['y-label'] == '' else form['y-label'] if y_axis_check else None

            x_axis_display = form['x-axis-display'] # x values on x-axis / legend
            display_gridlines = 'display-gridlines' in form # Display the gridlines
            rotate_x_labels = 'rotate-x-labels' in form # Rotate the x-axis labels
            display_values = 'display-values' in form # Display the values on top of the bars
            display_percentages = 'display-percentages' in form # Display the percentages on the sectors
            
            json_table        = form['table-data']
            json_systems      = form['systems-data']
            test_name         = form['test-name']
        except Exception as e:
            return redirect(am.url_for(am.get_endpoint_for_local_rule("/")) + "?error="+str(e))


        # Convert the json string into a dictionary similar to data
        data = json.loads(json_table)
        systems = json.loads(json_systems.replace("'", "\""))['SystemSample'] # Uses ' instead of " because passing it from __init__.py needs to be in a string format that doesn't conflict with the html form

        # Get the test type from the test name (e.g. "AB Test 1" -> "ab", "ab_text" -> "ab", "MOS Test 1" -> "mos")
        if test_name.lower().startswith("abx"): test_type = "abx"
        elif test_name.lower().startswith("ab"): test_type = "ab"
        elif test_name.lower().startswith("dmos"): test_type = "dmos"
        elif test_name.lower().startswith("mos"): test_type = "mos"
        elif test_name.lower().startswith("mushra"): test_type = "mushra"

        # Create a DataFrame sort it by index
        try: 
            data = analyse_results(
                system_json=systems,
                test_json=data,
                test_type=test_type
            )
        except Exception as e:
            return redirect(am.url_for(am.get_endpoint_for_local_rule("/")) + "?error="+str(e))
        
        
        df = pd.DataFrame(data)
        df = df.sort_index() 
        
        # Common chart options
        plt.style.use(chart_style)
        fig, ax = plt.subplots()
        ax.set_title(chart_title)
        ax.yaxis.grid(display_gridlines)
        ax.set_axisbelow(True)


        if test_type.lower() in ["ab", "abx"]:

            if ab_format == "bar":
                
                # Get the title and save path
                save_path = get_save_path(test_type+"_bar",test_name)

                if y_label == "Auto": y_label = "Count"  
                if x_label == "Auto": x_label = "System"


                for index, row in df.iterrows():
                    ax.bar(index, row[AB_COUNT_NAME])            

                if display_values:
                    for p in ax.patches:
                        ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 5), textcoords='offset points')

            elif ab_format == "pie":
                # Get the title and save path
                save_path = get_save_path(test_type+"_pie", test_name)

                # Pie chart
                # If display_percentages, display percentages
                # If x_axis_display is "x-axis", display system names next to the sectors
                # If x_axis_display is "legend", display system names in the legend

                if display_percentages and x_axis_display == "x-axis":
                    ax.pie(df[AB_COUNT_NAME], labels=df.index, autopct='%1.1f%%', startangle=90)
                elif not display_percentages and x_axis_display == "x-axis":
                    ax.pie(df[AB_COUNT_NAME], labels=df.index, startangle=90)
                elif display_percentages and x_axis_display == "legend":
                    ax.pie(df[AB_COUNT_NAME], autopct='%1.1f%%', startangle=90)
                    ax.legend(df.index, loc="best")
                elif not display_percentages and x_axis_display == "legend":
                    ax.pie(df[AB_COUNT_NAME], startangle=90)
                    ax.legend(df.index, loc="best")

                ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle

                def pie_values(display_percentages,display_values,values):
                    # display_percentages and display_values are booleans, values is a list of values
                    # TODO: https://stackoverflow.com/questions/41088236/how-to-have-actual-values-in-matplotlib-pie-chart-displayed
                    pass

                
        elif test_type.lower() in MUSHRA_TEST_TYPES:
            # Get the title and save path
            save_path = get_save_path(test_type+"_dot-plot", test_name)

            if x_label == "Auto": x_label = "System"
            if y_label == "Auto": y_label = "MUSHRA Score"

            ax.set_ylim(MUSHRA_MIN_SCORE,MUSHRA_MAX_SCORE)  # Set the y-axis limits
            for row in df.itertuples():
                x = row.Index
                y = getattr(row, MUSHRA_SCORE_NAME)
                yerr = getattr(row, MUSHRA_CONFIDENCE_INTERVAL_NAME)
                ax.errorbar(x, y, yerr=yerr, fmt=marker_type, capsize=4)
        
        elif test_type.lower() in MOS_TEST_TYPES:
            # Get the title and save path
            save_path = get_save_path(test_type+"_dot-plot", test_name)

            if x_label == "Auto": x_label = "System"
            if y_label == "Auto": y_label = "Mean Opinion Score"

            for row in df.itertuples():
                x = row.Index  # Assuming df.index is the x-value
                y = getattr(row, MOS_SCORE_NAME)
                yerr = getattr(row, MOS_CONFIDENCE_INTERVAL_NAME)
                ax.errorbar(x, y, yerr=yerr, fmt=marker_type, capsize=4)

        # Common options
        
        if not (test_type.lower() in AB_TEST_TYPES and ab_format == "pie"):
            if x_axis_display == "legend":
                ax.legend(df.index, loc="best")     
                ax.set_xticks([]) # Remove the x-axis ticks
                ax.set_xticklabels([]) # Remove the x-axis labels
            elif x_axis_display == "x-axis":
                ax.set_xticks(range(len(df.index)))                                
                ax.set_xticklabels(df.index, ha='right')
                if rotate_x_labels: ax.figure.autofmt_xdate()   
            ax.set_xlabel(x_label)
            ax.set_ylabel(y_label)

        # Save the plot
        print()
        plt.savefig(save_path, bbox_inches='tight')
        plt.close()

        return redirect(am.url_for(am.get_endpoint_for_local_rule("/")))

    @am.route('/delete_image', methods=["POST"])
    @am.connection_required
    def delete_image():
        """
        Delete an image from the results directory
        """

        # get the "src" from the url parameters. e.g. .../delete_image?src=results/2024-06-19T17:12:14.875142_ab_bar.png 
        src = request.form.get("src")

        # Get the image name and remove the url part
        image_name = src.split("/")[-1]

        # Results directory 
        path = current_app.config["FLEXEVAL_INSTANCE_RESULTS_DIR"]

        # Delete the image
        os.remove(os.path.join(path, image_name))

        return redirect(am.url_for(am.get_endpoint_for_local_rule("/")))

    @am.route('/delete_all_charts', methods=["POST"])
    @am.connection_required
    def delete_all_images():
        """
        Delete all images from the results directory
        """

        # Results directory 
        path = current_app.config["FLEXEVAL_INSTANCE_RESULTS_DIR"]

        # Delete all images
        for image in os.listdir(path):
            if image.endswith(".png"):
                os.remove(os.path.join(path, image))

        return redirect(am.url_for(am.get_endpoint_for_local_rule("/")))